
# FocusDown Summary
# 483 layers, 12767871 parameters, 12767871 gradients, 50.7 GFLOPs


# Parameters
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
nc: 80  # number of classes, required
nk: 0   # num of keypoints, (required, specify in data/project/xxx.yaml)


backbone:
  # [from, number, module, args] 
  [
   [-1, 1, RepConv, [64, 3, 1]],        # 0-P1/2
   [-1, 1, FocusDown, [64]],      # 1 Focus downsample

   [-1, 1, RepConv, [128, 3, 1]],       # 2-P2/4
   [-1, 1, FocusDown, [128]],      # 3 Focus downsample
   [-1, 3, C3xESE, [128, False, True]],     # 4 (c1, c2, n=1, ese=True, shortcut=True)

   [-1, 1, RepConv, [256, 3, 1]],     # 5 -P3/8
   [-1, 1, FocusDown, [256]],      # 6 Focus downsample
   [-1, 3, C3xESE, [256, False, True]],  # 7

   [-1, 1, AsymConv, [512, 3, 1]],    # 8-P4/16
   [-1, 1, FocusDown, [512]],      # 9 Focus downsample
   [-1, 9, C3xESE, [512, False, True]],  # 10


   [-1, 1, AsymConv, [1024, 3, 1]],   # 11-P5/32
   [-1, 1, FocusDown, [1024]],      # 12 Focus downsample
   [-1, 3, C3xESE, [1024, True, True]],     # 13 => has attention
   [-1, 1, SPPF, [1024, 5]],          # 14
  ]
  

neck:
  [[-1, 1, Conv, [512, 1, 1]],  # 15
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],   # 16
   [[-1, 10], 1, Concat, [1]],   # cat backbone P4 17
   [-1, 3, C3xESE, [512, False, False]],    # 18    (self, c1, c2, ese=True, shortcut=True) 

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],  
   [[-1, 7], 1, Concat, [1]],   # cat backbone P3
   [-1, 3, C3xESE, [256, False, False]],    # 22 (P3/8-small)

   [-1, 1, AsymConv, [256, 3, 1]],
   [-1, 1, FocusDown, [256]],      # 24 Focus downsample
   [[-1, 19], 1, Concat, [1]],    # cat head P4
   [-1, 3, C3xESE, [512, False, False]],    # 26 (P4/16-medium)

   [-1, 1, AsymConv, [512, 3, 1]],    # [-1, 1, DWConv, [512, 5, 2]],  
   [-1, 1, FocusDown, [512]],      # 28 Focus downsample
   [[-1, 15], 1, Concat, [1]],    # cat head P5
   [-1, 3, C3xESE, [1024, True, False]],    # 30 (P5/32-large)    => has attention
  ]

head:
  [
   [[22, 26, 30], 1, DetectX, [nc, nk]],    # Detect(P3, P4, P5)
  ]
